# 1. Import required modules
from pathlib import Path
import torch
import torch.nn.functional as F
from PIL import Image
import numpy as np
from torchvision import transforms
from torchvision.transforms.functional import gaussian_blur as tv_gaussian_blur
import cv2
import json

from anomalib.models import Patchcore
from visualize_heatmap import save_original_and_overlay_with_info


# ============================================================================
# ROIé€‰æ‹©å™¨ç±»ï¼ˆæ•´åˆè‡ª roi_selector.pyï¼‰
# ============================================================================

class ROISelector:
    """ROIé€‰æ‹©å·¥å…·ç±»."""
    
    def __init__(self, image_path):
        """åˆå§‹åŒ–ROIé€‰æ‹©å™¨.
        
        Args:
            image_path (str): è¾“å…¥å›¾åƒè·¯å¾„
        """
        self.image_path = Path(image_path)
        self.image = cv2.imread(str(image_path))
        
        if self.image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        self.display_image = self.image.copy()
        self.rois = []  # å­˜å‚¨æ‰€æœ‰ROI [(x, y, w, h), ...]
        self.current_roi = None
        self.drawing = False
        self.start_point = None
        
        self.window_name = "ROI Selector - 's':Save  'r':Reset  'q':Quit"
        
    def mouse_callback(self, event, x, y, flags, param):
        """é¼ æ ‡äº‹ä»¶å›è°ƒå‡½æ•°."""
        if event == cv2.EVENT_LBUTTONDOWN:
            self.drawing = True
            self.start_point = (x, y)
            
        elif event == cv2.EVENT_MOUSEMOVE:
            if self.drawing:
                self.display_image = self.image.copy()
                self._draw_existing_rois()
                # æ­£åœ¨æ‹–åŠ¨çš„çŸ©å½¢æ¡†ï¼ˆç²—çº¿æ¡ï¼Œæ›´é†’ç›®ï¼‰
                cv2.rectangle(self.display_image, self.start_point, (x, y), (0, 255, 0), 5)
                cv2.imshow(self.window_name, self.display_image)
                
        elif event == cv2.EVENT_LBUTTONUP:
            if self.drawing:
                self.drawing = False
                end_point = (x, y)
                
                # è®¡ç®—ROIåæ ‡(ç¡®ä¿x1<x2, y1<y2)
                x1, x2 = min(self.start_point[0], end_point[0]), max(self.start_point[0], end_point[0])
                y1, y2 = min(self.start_point[1], end_point[1]), max(self.start_point[1], end_point[1])
                
                # æ·»åŠ ROIï¼ˆå¦‚æœå°ºå¯¸æœ‰æ•ˆï¼‰
                if x2 - x1 > 5 and y2 - y1 > 5:
                    self.rois.append((x1, y1, x2 - x1, y2 - y1))
                    print(f"   âœ“ æ·»åŠ ROI #{len(self.rois)}: ({x1}, {y1}, {x2-x1}, {y2-y1})")
                
                self._update_display()
    
    def _draw_existing_rois(self):
        """åœ¨æ˜¾ç¤ºå›¾åƒä¸Šç»˜åˆ¶æ‰€æœ‰å·²å­˜åœ¨çš„ROI."""
        for idx, (x, y, w, h) in enumerate(self.rois):
            # å·²å®Œæˆçš„ROIçŸ©å½¢æ¡†ï¼ˆç²—çº¿æ¡ï¼‰
            cv2.rectangle(self.display_image, (x, y), (x+w, y+h), (0, 255, 0), 4)
            # ROIæ ‡ç­¾æ–‡å­—
            cv2.putText(self.display_image, f"ROI {idx+1}", (x, y-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    def _update_display(self, message=None, message_color=(0, 255, 0)):
        """æ›´æ–°æ˜¾ç¤ºå›¾åƒ.
        
        Args:
            message: è¦æ˜¾ç¤ºçš„ä¸´æ—¶æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
            message_color: æ¶ˆæ¯é¢œè‰²ï¼Œé»˜è®¤ç»¿è‰²
        """
        self.display_image = self.image.copy()
        self._draw_existing_rois()
        
        # æ·»åŠ æç¤ºä¿¡æ¯èƒŒæ™¯
        h, w = self.image.shape[:2]
        info_bg = np.zeros((80, w, 3), dtype=np.uint8)
        cv2.putText(info_bg, f"ROI Count: {len(self.rois)}", (10, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(info_bg, "'s': Save  'r': Reset  'q': Quit", (10, 55),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        # å¦‚æœæœ‰ä¸´æ—¶æ¶ˆæ¯ï¼Œåœ¨å›¾åƒä¸Šå åŠ æ˜¾ç¤º
        if message:
            # åœ¨å›¾åƒä¸­å¤®ä¸Šæ–¹æ˜¾ç¤ºæ¶ˆæ¯
            font_scale = 2.5  # å­—ä½“å¤§å°ï¼ˆå¢å¤§ï¼‰
            font_thickness = 4  # å­—ä½“ç²—ç»†ï¼ˆå¢åŠ ï¼‰
            text_size = cv2.getTextSize(message, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)[0]
            text_x = (w - text_size[0]) // 2
            text_y = 120  # å‘ä¸‹ç§»åŠ¨ä¸€ç‚¹
            
            # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
            overlay = self.display_image.copy()
            padding = 30  # å¢åŠ è¾¹è·
            cv2.rectangle(overlay, 
                         (text_x - padding, text_y - text_size[1] - padding),
                         (text_x + text_size[0] + padding, text_y + padding),
                         (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, self.display_image, 0.3, 0, self.display_image)
            
            # ç»˜åˆ¶æ¶ˆæ¯æ–‡æœ¬
            cv2.putText(self.display_image, message, (text_x, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, message_color, font_thickness)
        
        display = np.vstack([self.display_image, info_bg])
        cv2.imshow(self.window_name, display)
    
    def create_mask(self):
        """åˆ›å»ºROI maskï¼ˆç™½è‰²=ROIåŒºåŸŸï¼Œé»‘è‰²=å¿½ç•¥åŒºåŸŸï¼‰."""
        h, w = self.image.shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        for x, y, roi_w, roi_h in self.rois:
            mask[y:y+roi_h, x:x+roi_w] = 255
        
        return mask
    
    def save_roi_config(self, output_path=None, save_dir=None):
        """ä¿å­˜ROIé…ç½®åˆ°JSONæ–‡ä»¶."""
        if not self.rois:
            print("   âš ï¸  æ²¡æœ‰ROIå¯ä¿å­˜")
            return None
        
        # ç¡®å®šä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ä¿å­˜åˆ° predict.py æ‰€åœ¨ç›®å½•ï¼‰
        if save_dir is None:
            save_dir = Path(__file__).parent  # tools/tiled_ensemble/
        else:
            save_dir = Path(save_dir)
        
        if output_path is None:
            output_path = save_dir / "roi.json"
        
        config = {
            "image": str(self.image_path.name),
            "image_size": {
                "width": self.image.shape[1],
                "height": self.image.shape[0]
            },
            "rois": [
                {"x": x, "y": y, "width": w, "height": h}
                for x, y, w, h in self.rois
            ]
        }
        
        with open(output_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        # åŒæ—¶ä¿å­˜maskå›¾åƒ
        mask = self.create_mask()
        mask_path = save_dir / "roi_mask.png"
        cv2.imwrite(str(mask_path), mask)
        
        print(f"   âœ… ROIé…ç½®å·²ä¿å­˜: {output_path}")
        print(f"   âœ… ROI maskå·²ä¿å­˜: {mask_path}")
        
        return str(output_path)
    
    def run(self, save_dir=None):
        """è¿è¡ŒROIé€‰æ‹©å™¨.
        
        Args:
            save_dir: ROIæ–‡ä»¶ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•
        """
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.setMouseCallback(self.window_name, self.mouse_callback)
        
        self._update_display()
        
        saved_path = None
        message_timer = 0  # æ¶ˆæ¯æ˜¾ç¤ºè®¡æ—¶å™¨
        current_message = None
        message_color = (0, 255, 0)
        
        while True:
            key = cv2.waitKey(1) & 0xFF
            
            # æ›´æ–°æ¶ˆæ¯æ˜¾ç¤º
            if message_timer > 0:
                message_timer -= 1
                self._update_display(current_message, message_color)
                if message_timer == 0:
                    current_message = None
                    self._update_display()
            
            if key == ord('q'):
                # é€€å‡ºï¼šå¦‚æœå·²ä¿å­˜åˆ™è¿”å›è·¯å¾„ï¼Œå¦åˆ™è¿”å› None
                break
            elif key == ord('r'):
                # é‡ç½®ROI
                self.rois = []
                print("   âœ… å·²é‡ç½®æ‰€æœ‰ROI")
                # æ˜¾ç¤ºå¼¹çª—æç¤º
                current_message = "ROI Reset!"
                message_color = (0, 165, 255)  # æ©™è‰²
                message_timer = 100  # æ˜¾ç¤ºçº¦1ç§’ï¼ˆ100å¸§ @ 1ms/frameï¼‰
                self._update_display(current_message, message_color)
            elif key == ord('s'):
                # ä¿å­˜ROIï¼Œä½†ç»§ç»­ç¼–è¾‘
                saved_path = self.save_roi_config(save_dir=save_dir)
                if saved_path:
                    print("   ğŸ’¡ ç»§ç»­ç¼–è¾‘æˆ–æŒ‰ 'q' é€€å‡º")
                    # æ˜¾ç¤ºå¼¹çª—æç¤º
                    current_message = "ROI Saved"
                    message_color = (0, 255, 0)  # ç»¿è‰²
                    message_timer = 100  # æ˜¾ç¤ºçº¦1ç§’
                    self._update_display(current_message, message_color)
                else:
                    # ä¿å­˜å¤±è´¥
                    current_message = "No ROI to Save"
                    message_color = (0, 0, 255)  # çº¢è‰²
                    message_timer = 100
                    self._update_display(current_message, message_color)
        
        cv2.destroyAllWindows()
        return saved_path


def load_roi_mask(roi_config_path):
    """ä»ROIé…ç½®æ–‡ä»¶åŠ è½½mask."""
    roi_config_path = Path(roi_config_path)
    
    if not roi_config_path.exists():
        raise FileNotFoundError(f"ROIé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {roi_config_path}")
    
    with open(roi_config_path, 'r') as f:
        config = json.load(f)
    
    # åˆ›å»ºmask
    h = config["image_size"]["height"]
    w = config["image_size"]["width"]
    mask = np.zeros((h, w), dtype=np.uint8)
    
    for roi in config["rois"]:
        x, y = roi["x"], roi["y"]
        roi_w, roi_h = roi["width"], roi["height"]
        mask[y:y+roi_h, x:x+roi_w] = 255
    
    return mask


# ============================================================================
# PCBèƒŒæ™¯è£å‰ªåŠŸèƒ½ï¼ˆä¸ pcb_crop_transform.py ç›¸åŒçš„ç®—æ³•ï¼‰
# ============================================================================

def detect_and_crop_pcb(image: Image.Image, padding: int = 10, min_area_ratio: float = 0.1) -> Image.Image | None:
    """æ£€æµ‹å¹¶è£å‰ªPCBèƒŒæ™¯.
    
    Args:
        image (Image.Image): è¾“å…¥PILå›¾åƒ
        padding (int): è£å‰ªè¾¹è·ï¼ˆåƒç´ ï¼‰. Defaults to 10.
        min_area_ratio (float): PCBæœ€å°é¢ç§¯å æ¯”. Defaults to 0.1.
        
    Returns:
        Image.Image | None: è£å‰ªåçš„å›¾åƒï¼Œå¤±è´¥è¿”å› None
    """
    # PIL -> numpy (RGB)
    image_np = np.array(image)
    
    # RGB -> BGR for OpenCV
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    
    h, w = image_bgr.shape[:2]
    
    # æ£€æµ‹è¾¹ç•Œ
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (9, 9), 0)
    edges = cv2.Canny(blurred, 30, 100)
    
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 20))
    edges = cv2.dilate(edges, kernel, iterations=2)
    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
    
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        return None
    
    largest = max(contours, key=cv2.contourArea)
    area = cv2.contourArea(largest)
    
    if area < (h * w * min_area_ratio):
        return None
    
    x, y, w_pcb, h_pcb = cv2.boundingRect(largest)
    
    # è£å‰ªï¼ˆåŠ paddingï¼‰
    x1 = max(0, x - padding)
    y1 = max(0, y - padding)
    x2 = min(w, x + w_pcb + padding)
    y2 = min(h, y + h_pcb + padding)
    
    cropped_bgr = image_bgr[y1:y2, x1:x2]
    
    # BGR -> RGB -> PIL
    cropped_rgb = cv2.cvtColor(cropped_bgr, cv2.COLOR_BGR2RGB)
    return Image.fromarray(cropped_rgb)


# ============================================================================
# åŠ è½½é…ç½®æ–‡ä»¶
# ============================================================================

import yaml

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = Path(__file__).parent / "predict_config.yaml"

if not CONFIG_FILE.exists():
    print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
    print(f"è¯·ç¡®ä¿ predict_config.yaml æ–‡ä»¶åœ¨ tools/tiled_ensemble/ ç›®å½•ä¸‹")
    exit(1)

print("="*70)
print("ğŸš€ Tiled Ensemble é›†æˆé¢„æµ‹")
print("="*70)
print(f"ğŸ“ åŠ è½½é…ç½®æ–‡ä»¶: {CONFIG_FILE.name}\n")

with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# æå–é…ç½®å‚æ•°
CHECKPOINT_DIR = Path(config['paths']['checkpoint_dir'])
INPUT_DIR = Path(config['paths']['input_dir'])
OUTPUT_DIR = Path(config['paths']['output_dir'])
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

IMAGE_SIZE = config['image']['image_size']
TILE_SIZE = config['image']['tile_size']

APPLY_SEAM_SMOOTHING = config['seam_smoothing']['apply']
SEAM_SIGMA = config['seam_smoothing']['sigma']
SEAM_WIDTH = config['seam_smoothing']['width']

USE_ROI = config['roi']['enable']
ROI_CONFIG_PATH = config['roi']['config_path']

ENABLE_PCB_CROP = config['pcb_crop']['enable']
PCB_CROP_PADDING = config['pcb_crop']['padding']
PCB_MIN_AREA_RATIO = config['pcb_crop']['min_area_ratio']

NORMALIZED_THRESHOLD = config['threshold']['normalized_threshold']

print("âš™ï¸  é…ç½®ä¿¡æ¯:")
print(f"   - è¾“å…¥ç›®å½•: {INPUT_DIR}")
print(f"   - è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
print(f"   - æ¨¡å‹ç›®å½•: {CHECKPOINT_DIR}")
print(f"   - åˆ¤æ–­é˜ˆå€¼: {NORMALIZED_THRESHOLD}")
print(f"   - PCBè£å‰ª: {'å¯ç”¨' if ENABLE_PCB_CROP else 'ç¦ç”¨'}")
print(f"   - ROIè¿‡æ»¤: {'å¯ç”¨' if USE_ROI else 'ç¦ç”¨'}")
print(f"   - æ¥ç¼å¹³æ»‘: {'å¯ç”¨' if APPLY_SEAM_SMOOTHING else 'ç¦ç”¨'}")
print("="*70)
print("å·¥ä½œåŸç†ï¼š")
print("  0. è‡ªåŠ¨è£å‰ªPCBèƒŒæ™¯")
print("  1. å›¾åƒè°ƒæ•´ä¸º 512Ã—512")
print("  2. åˆ‡åˆ†æˆ 2Ã—2 = 4 ä¸ª tilesï¼ˆæ¯ä¸ª256Ã—256ï¼‰")
print("  3. æ¯ä¸ªtileç”±å¯¹åº”çš„æ¨¡å‹é¢„æµ‹ï¼š")
print("     - model0_0.ckpt â†’ Tile 0 (å·¦ä¸Š)")
print("     - model0_1.ckpt â†’ Tile 1 (å³ä¸Š)")
print("     - model1_0.ckpt â†’ Tile 2 (å·¦ä¸‹)")
print("     - model1_1.ckpt â†’ Tile 3 (å³ä¸‹)")
print("  4. åˆå¹¶æ‰€æœ‰tileçš„é¢„æµ‹ç»“æœ")
print("="*70)

# 3. åŠ è½½è®­ç»ƒæ—¶çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
print("\n[æ­¥éª¤ 1/5] ğŸ“Š åŠ è½½å½’ä¸€åŒ–ç»Ÿè®¡ä¿¡æ¯...")
import json
stats_file = CHECKPOINT_DIR / "stats.json"
if not stats_file.exists():
    print(f"   âŒ æ‰¾ä¸åˆ° stats.json: {stats_file}")
    print(f"   è¿™ä¸ªæ–‡ä»¶åŒ…å«äº†è®­ç»ƒæ—¶çš„å½’ä¸€åŒ–å‚æ•°ï¼Œæ˜¯å¿…éœ€çš„ï¼")
    exit(1)

with open(stats_file, 'r') as f:
    stats = json.load(f)

# è·å–å½’ä¸€åŒ–å‚æ•°
ANOMALY_MAP_MIN = stats["minmax"]["anomaly_map"]["min"]
ANOMALY_MAP_MAX = stats["minmax"]["anomaly_map"]["max"]
PIXEL_THRESHOLD = stats["pixel_threshold"]  # ç”¨äºanomaly_mapå½’ä¸€åŒ–
IMAGE_THRESHOLD = stats["image_threshold"]  # ç”¨äºpred_scoreå½’ä¸€åŒ–

PRED_SCORE_MIN = stats["minmax"]["pred_score"]["min"]
PRED_SCORE_MAX = stats["minmax"]["pred_score"]["max"]

print(f"   âœ… Anomaly Map èŒƒå›´: [{ANOMALY_MAP_MIN:.4f}, {ANOMALY_MAP_MAX:.4f}]")
print(f"   âœ… Pixel é˜ˆå€¼: {PIXEL_THRESHOLD:.4f} (å½’ä¸€åŒ–å = 0.5)")
print(f"   âœ… Pred Score èŒƒå›´: [{PRED_SCORE_MIN:.4f}, {PRED_SCORE_MAX:.4f}]")
print(f"   âœ… Image é˜ˆå€¼: {IMAGE_THRESHOLD:.4f} (å½’ä¸€åŒ–å = 0.5)")

# 4. åŠ è½½4ä¸ªæ¨¡å‹
print("\n[æ­¥éª¤ 2/5] ğŸ” åŠ è½½4ä¸ªæ¨¡å‹...")
models = {}
model_files = [
    ("model0_0.ckpt", (0, 0)),  # å·¦ä¸Š
    ("model0_1.ckpt", (0, 1)),  # å³ä¸Š
    ("model1_0.ckpt", (1, 0)),  # å·¦ä¸‹
    ("model1_1.ckpt", (1, 1)),  # å³ä¸‹
]

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"   ä½¿ç”¨è®¾å¤‡: {device}")

for model_file, position in model_files:
    model_path = CHECKPOINT_DIR / model_file
    if not model_path.exists():
        print(f"   âŒ æ‰¾ä¸åˆ°æ¨¡å‹: {model_path}")
        print(f"   è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
        exit(1)
    
    # åŠ è½½checkpoint
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    # ç¦ç”¨é¢„å¤„ç†å™¨å’Œåå¤„ç†å™¨ï¼Œå› ä¸ºæˆ‘ä»¬æ‰‹åŠ¨å¤„ç†
    model = Patchcore(pre_processor=False, post_processor=False)
    model.load_state_dict(checkpoint["state_dict"], strict=False)  # strict=Falseå¿½ç•¥post_processorå‚æ•°
    model.to(device)
    model.eval()  # ç¡®ä¿æ˜¯è¯„ä¼°æ¨¡å¼
    
    models[position] = model
    print(f"   âœ… {model_file} â†’ Tile ä½ç½® {position}")

print(f"   æˆåŠŸåŠ è½½ {len(models)} ä¸ªæ¨¡å‹")


# 5. å›¾åƒé¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])


def normalize_anomaly_map(anomaly_map, threshold, min_val, max_val):
    """
    å°†anomaly mapå½’ä¸€åŒ–åˆ°0-1èŒƒå›´
    
    ä½¿ç”¨ä¸è®­ç»ƒpipelineç›¸åŒçš„å½’ä¸€åŒ–æ–¹æ³•ï¼š
    å°†thresholdæ˜ å°„åˆ°0.5ï¼Œå…¶ä»–å€¼æŒ‰æ¯”ä¾‹ç¼©æ”¾
    """
    # ä½¿ç”¨Anomalibçš„å½’ä¸€åŒ–å…¬å¼
    normalized = ((anomaly_map - threshold) / (max_val - min_val)) + 0.5
    # é™åˆ¶åœ¨0-1èŒƒå›´å†…
    normalized = torch.clamp(normalized, 0.0, 1.0)
    return normalized


def split_into_tiles(image_tensor):
    """å°† 512Ã—512 å›¾åƒåˆ‡åˆ†æˆ 2Ã—2 ä¸ª 256Ã—256 tiles"""
    tiles = {}
    for i in range(2):  # è¡Œ
        for j in range(2):  # åˆ—
            # æå–tile
            tile = image_tensor[
                :,
                i * TILE_SIZE : (i + 1) * TILE_SIZE,
                j * TILE_SIZE : (j + 1) * TILE_SIZE,
            ]
            tiles[(i, j)] = tile
    return tiles


def merge_tiles(tile_predictions):
    """
    åˆå¹¶4ä¸ªtileçš„é¢„æµ‹ç»“æœï¼ˆä¸å½’ä¸€åŒ–ï¼Œä¿æŒåŸå§‹å€¼ï¼‰
    
    Args:
        tile_predictions: å­—å…¸ï¼Œ{(i,j): {'anomaly_map': tensor, 'pred_score': float}}
    
    Returns:
        merged_anomaly_map: åˆå¹¶åçš„anomaly map
        merged_pred_score: æ‰€æœ‰tilesçš„å¹³å‡pred_score
    """
    # åˆ›å»ºå®Œæ•´çš„anomaly map
    full_map = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), device=device)
    
    # æ”¶é›†æ‰€æœ‰tileçš„pred_scoreï¼ˆç”¨äºè®¡ç®—å¹³å‡å€¼ï¼‰
    tile_scores = []
    
    for (i, j), pred_data in tile_predictions.items():
        pred_map = pred_data['anomaly_map']
        pred_score = pred_data['pred_score']
        
        # ç¡®ä¿pred_mapæ˜¯2Dçš„
        if pred_map.dim() > 2:
            pred_map = pred_map.squeeze()
        
        # è°ƒæ•´å¤§å°åˆ°256Ã—256ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if pred_map.shape != (TILE_SIZE, TILE_SIZE):
            pred_map = F.interpolate(
                pred_map.unsqueeze(0).unsqueeze(0),
                size=(TILE_SIZE, TILE_SIZE),
                mode='bilinear',
                align_corners=False
            ).squeeze()
        
        # æ”¾åˆ°å¯¹åº”ä½ç½®ï¼ˆä¸å½’ä¸€åŒ–ï¼Œä¿æŒåŸå§‹å€¼ï¼ï¼‰
        full_map[
            i * TILE_SIZE : (i + 1) * TILE_SIZE,
            j * TILE_SIZE : (j + 1) * TILE_SIZE,
        ] = pred_map
        
        # æ”¶é›†pred_score
        tile_scores.append(pred_score)
    
    # pred_scoreæ˜¯æ‰€æœ‰tilesçš„å¹³å‡å€¼ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    avg_pred_score = sum(tile_scores) / len(tile_scores)
    
    return full_map, avg_pred_score


def smooth_seams(anomaly_map, sigma=2, width_ratio=0.1):
    """å¯¹ tile æ¥ç¼åŒºåŸŸåšé«˜æ–¯å¹³æ»‘ï¼Œå‡è½»ç¡¬æ‹¼æ¥ç—•è¿¹ã€‚"""
    # anomaly_map: [H, W]ï¼Œæ­¤å¤„ H=W=IMAGE_SIZE
    h, w = anomaly_map.shape
    assert h == IMAGE_SIZE and w == IMAGE_SIZE, "anomaly_map å°ºå¯¸å¿…é¡»ç­‰äº IMAGE_SIZE"

    # è®¡ç®—æ¥ç¼åŒºåŸŸå®½åº¦ï¼ˆè‡³å°‘ 1 åƒç´ ï¼‰
    seam_w = max(1, int(width_ratio * TILE_SIZE))

    # æ„é€ æ¥ç¼ maskï¼ˆåªåœ¨æ¥ç¼é™„è¿‘è¿›è¡Œå¹³æ»‘èåˆï¼‰
    mask = torch.zeros_like(anomaly_map)
    # æ¨ªå‘æ¥ç¼ï¼ˆè¡Œæ–¹å‘ï¼‰ï¼šä½äº TILE_SIZE è¡Œé™„è¿‘
    row_start = max(0, TILE_SIZE - seam_w)
    row_end = min(IMAGE_SIZE, TILE_SIZE + seam_w)
    mask[row_start:row_end, :] = 1.0
    # çºµå‘æ¥ç¼ï¼ˆåˆ—æ–¹å‘ï¼‰ï¼šä½äº TILE_SIZE åˆ—é™„è¿‘
    col_start = max(0, TILE_SIZE - seam_w)
    col_end = min(IMAGE_SIZE, TILE_SIZE + seam_w)
    mask[:, col_start:col_end] = 1.0

    # ç”Ÿæˆåˆé€‚çš„æ ¸å¤§å°ï¼ˆå¥‡æ•°ï¼‰
    ksize = int(6 * sigma + 1)
    if ksize % 2 == 0:
        ksize += 1
    ksize = max(3, ksize)

    # å¯¹æ•´å¹…å›¾åšé«˜æ–¯æ¨¡ç³Šï¼Œå†ç”¨ mask åªæ›¿æ¢æ¥ç¼åŒºåŸŸ
    blurred = tv_gaussian_blur(anomaly_map.unsqueeze(0), kernel_size=ksize, sigma=sigma).squeeze(0)
    smoothed = anomaly_map * (1.0 - mask) + blurred * mask
    return smoothed


# 6. ROI é€‰æ‹©ï¼ˆå¦‚æœå¯ç”¨ä¸”æœªæŒ‡å®šROIæ–‡ä»¶ï¼‰
if USE_ROI and ROI_CONFIG_PATH is None:
    print("\n[æ­¥éª¤ 3/6] ğŸ¯ é€‰æ‹© ROI åŒºåŸŸ...")
    print("="*70)
    
    # è·å–é¢„æµ‹ç›®å½•ä¸­çš„å›¾åƒåˆ—è¡¨
    temp_image_files = list(INPUT_DIR.glob("*.jpg")) + \
                      list(INPUT_DIR.glob("*.jpeg")) + \
                      list(INPUT_DIR.glob("*.png"))
    
    if len(temp_image_files) == 0:
        print(f"   âŒ åœ¨ {INPUT_DIR} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        print(f"   è¯·å°†è¦é¢„æµ‹çš„å›¾ç‰‡æ”¾åˆ°è¯¥æ–‡ä»¶å¤¹ä¸­")
        exit(1)
    
    # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡æ¥é€‰æ‹©ROIï¼ˆæˆ–è®©ç”¨æˆ·é€‰æ‹©ï¼‰
    print(f"   æ‰¾åˆ° {len(temp_image_files)} å¼ å›¾åƒ")
    print(f"\n   å‡†å¤‡å‚è€ƒå›¾ç‰‡ç”¨äºé€‰æ‹©ROIåŒºåŸŸ...")
    print(f"   å‚è€ƒå›¾ç‰‡: {temp_image_files[0].name}")
    
    # ğŸ”‘ å…³é”®ä¿®æ”¹ï¼šå…ˆè£å‰ª PCBï¼Œç„¶ååœ¨è£å‰ªåçš„å›¾ç‰‡ä¸Šé€‰æ‹© ROI
    try:
        reference_image = Image.open(temp_image_files[0]).convert("RGB")
        print(f"   åŸå§‹å°ºå¯¸: {reference_image.size[0]}Ã—{reference_image.size[1]}")
        
        # PCB è£å‰ª
        if ENABLE_PCB_CROP:
            cropped_ref = detect_and_crop_pcb(reference_image, padding=PCB_CROP_PADDING, min_area_ratio=PCB_MIN_AREA_RATIO)
            if cropped_ref is not None:
                print(f"   âœ‚ï¸  PCBè£å‰ª: {reference_image.size[0]}Ã—{reference_image.size[1]} â†’ {cropped_ref.size[0]}Ã—{cropped_ref.size[1]}")
                reference_image = cropped_ref
            else:
                print(f"   âš ï¸  PCBè£å‰ªå¤±è´¥ï¼Œä½¿ç”¨åŸå›¾")
        
        # ä¿å­˜ä¸´æ—¶è£å‰ªå›¾ç”¨äº ROI é€‰æ‹©
        temp_cropped_path = Path(__file__).parent / "temp_cropped_for_roi.png"
        reference_image.save(temp_cropped_path)
        print(f"   âœ… è£å‰ªåå›¾ç‰‡å·²ä¿å­˜ï¼ˆç”¨äºROIé€‰æ‹©ï¼‰")
        
        print(f"\n   æ“ä½œè¯´æ˜:")
        print(f"     - å·¦é”®æ‹–åŠ¨: é€‰æ‹©çŸ©å½¢ROIåŒºåŸŸ")
        print(f"     - 's': ä¿å­˜ROIé…ç½®ï¼ˆå¯å¤šæ¬¡ä¿å­˜ï¼‰")
        print(f"     - 'r': é‡ç½®æ‰€æœ‰ROI")
        print(f"     - 'q': ç¡®è®¤é€€å‡ºå¹¶ç»§ç»­é¢„æµ‹")
        print("="*70)
        
        # predict.py æ‰€åœ¨ç›®å½•ï¼ˆä¿å­˜ROIæ–‡ä»¶çš„ä½ç½®ï¼‰
        script_dir = Path(__file__).parent
        
        # ä½¿ç”¨è£å‰ªåçš„å›¾ç‰‡è¿›è¡Œ ROI é€‰æ‹©
        selector = ROISelector(str(temp_cropped_path))
        saved_roi_path = selector.run(save_dir=script_dir)
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        if temp_cropped_path.exists():
            temp_cropped_path.unlink()
            print(f"   ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
        
        
        if saved_roi_path:
            ROI_CONFIG_PATH = saved_roi_path
            print(f"\n   âœ… ROIé…ç½®å·²ä¿å­˜ï¼ˆåŸºäºè£å‰ªåå›¾ç‰‡ï¼‰ï¼Œå°†åº”ç”¨äºæ‰€æœ‰å›¾åƒ")
            print(f"   ğŸ“ æ–‡ä»¶: {Path(saved_roi_path).name}")
        else:
            print(f"\n   âš ï¸  æœªä¿å­˜ROIé…ç½®ï¼Œå°†ä¸ä½¿ç”¨ROIè¿‡æ»¤")
            USE_ROI = False
    except Exception as e:
        print(f"\n   âŒ ROIé€‰æ‹©å¤±è´¥: {e}")
        print(f"   å°†ä¸ä½¿ç”¨ROIè¿‡æ»¤")
        USE_ROI = False
        import traceback
        traceback.print_exc()

# 7. éå†æ‰€æœ‰å›¾åƒè¿›è¡Œé¢„æµ‹
print("\n[æ­¥éª¤ 4/6] ğŸ“‚ åŠ è½½å›¾åƒ...")
image_files = list(INPUT_DIR.glob("*.jpg")) + \
              list(INPUT_DIR.glob("*.jpeg")) + \
              list(INPUT_DIR.glob("*.png"))

if len(image_files) == 0:
    print(f"   âŒ åœ¨ {INPUT_DIR} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
    print(f"   è¯·å°†è¦é¢„æµ‹çš„å›¾ç‰‡æ”¾åˆ°è¯¥æ–‡ä»¶å¤¹ä¸­")
    exit(1)

print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")


print("\n[æ­¥éª¤ 5/6] ğŸ”® ä½¿ç”¨4ä¸ªæ¨¡å‹è¿›è¡Œé›†æˆé¢„æµ‹...")
print("="*70)

for img_idx, image_path in enumerate(image_files, 1):
    print(f"\n[{img_idx}/{len(image_files)}] å¤„ç†: {image_path.name}")
    
    # è¯»å–å›¾åƒ
    image = Image.open(image_path).convert("RGB")
    original_size = image.size
    print(f"   åŸå§‹å°ºå¯¸: {original_size[0]}Ã—{original_size[1]}")
    
    # PCBèƒŒæ™¯è£å‰ªï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if ENABLE_PCB_CROP:
        cropped = detect_and_crop_pcb(image, padding=PCB_CROP_PADDING, min_area_ratio=PCB_MIN_AREA_RATIO)
        if cropped is not None:
            print(f"   âœ‚ï¸  PCBè£å‰ª: {image.size[0]}Ã—{image.size[1]} â†’ {cropped.size[0]}Ã—{cropped.size[1]}")
            image = cropped
            original_size = image.size  # æ›´æ–°åŸå§‹å°ºå¯¸ä¸ºè£å‰ªåçš„å°ºå¯¸
        else:
            print(f"   âš ï¸  PCBè£å‰ªå¤±è´¥ï¼Œä½¿ç”¨åŸå›¾")
    
    # åŠ è½½ROI maskï¼ˆå¦‚æœå¯ç”¨ï¼‰
    roi_mask = None
    if USE_ROI and ROI_CONFIG_PATH:
        # ä½¿ç”¨æŒ‡å®šçš„ROIé…ç½®æ–‡ä»¶ï¼ˆæ‰¹é‡åº”ç”¨ç›¸åŒROIï¼‰
        try:
            roi_mask = load_roi_mask(ROI_CONFIG_PATH)
            if img_idx == 1:  # åªåœ¨ç¬¬ä¸€å¼ å›¾ç‰‡æ—¶æ‰“å°
                print(f"   âœ… ROIé…ç½®: {Path(ROI_CONFIG_PATH).name}")
        except Exception as e:
            print(f"   âš ï¸  åŠ è½½ROI maskå¤±è´¥: {e}")
            roi_mask = None
    
    # é¢„å¤„ç†ï¼šè°ƒæ•´ä¸º512Ã—512å¹¶å½’ä¸€åŒ–
    image_tensor = transform(image).unsqueeze(0).to(device)  # [1, 3, 512, 512]
    print(f"   è°ƒæ•´ä¸º 512Ã—512")
    
    # âœ… å…³é”®ä¿®æ­£ï¼šå…ˆåˆ‡åˆ†å›¾åƒï¼Œç„¶åæ¯ä¸ªæ¨¡å‹é¢„æµ‹å¯¹åº”çš„tile
    # æ­¥éª¤1: å°†512Ã—512å›¾åƒåˆ‡åˆ†æˆ4ä¸ª256Ã—256çš„tiles
    tiles = split_into_tiles(image_tensor.squeeze(0))  # ç§»é™¤batchç»´åº¦
    print(f"   åˆ‡åˆ†æˆ {len(tiles)} ä¸ªtiles (æ¯ä¸ª256Ã—256)")
    
    # æ­¥éª¤2: æ¯ä¸ªæ¨¡å‹é¢„æµ‹å¯¹åº”ä½ç½®çš„tile
    tile_predictions = {}
    with torch.no_grad():
        for position, model in models.items():
            # å–å‡ºå¯¹åº”ä½ç½®çš„tileï¼ˆ256Ã—256ï¼‰
            tile = tiles[position].unsqueeze(0)  # [1, 3, 256, 256]
            
            # ç”¨è¿™ä¸ªtileé¢„æµ‹
            output = model(tile)
            anomaly_map = output.anomaly_map.squeeze()  # è·å–anomaly map  
            pred_score = output.pred_score.item()  # è·å–pred_score
            
            tile_predictions[position] = {
                'anomaly_map': anomaly_map,
                'pred_score': pred_score
            }
            print(f"   âœ“ Tile {position} é¢„æµ‹å®Œæˆ (åŸå§‹åˆ†æ•°: {pred_score:.2f})")
    
    # åˆå¹¶æ‰€æœ‰tileçš„é¢„æµ‹ï¼ˆä¿æŒåŸå§‹å€¼ï¼‰
    print(f"   ğŸ”„ åˆå¹¶4ä¸ªtileçš„é¢„æµ‹ç»“æœ...")
    merged_anomaly_map, merged_pred_score = merge_tiles(tile_predictions)

    # å¯é€‰ï¼šå¯¹æ¥ç¼åŒºåŸŸåšå¹³æ»‘ï¼ˆä¸å®˜æ–¹ pipeline çš„ SeamSmoothing å¯¹é½ï¼‰
    if APPLY_SEAM_SMOOTHING:
        merged_anomaly_map = smooth_seams(
            merged_anomaly_map,
            sigma=SEAM_SIGMA,
            width_ratio=SEAM_WIDTH,
        )
    
    print(f"   ğŸ“Š åˆå¹¶åçš„åŸå§‹å€¼:")
    print(f"      - Pred Score (tileså¹³å‡): {merged_pred_score:.2f}")
    print(f"      - Anomaly Map æœ€å¤§å€¼: {merged_anomaly_map.max().item():.2f}")
    
    # å½’ä¸€åŒ– (IMAGEçº§åˆ«ï¼Œä¸è®­ç»ƒæ—¶ä¸€è‡´)
    print(f"   ğŸ¯ å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´...")
    
    # å½’ä¸€åŒ– pred_score
    normalized_pred_score = normalize_anomaly_map(
        torch.tensor(merged_pred_score, device=device),
        IMAGE_THRESHOLD,    # threshold
        PRED_SCORE_MIN,     # min_val
        PRED_SCORE_MAX      # max_val
    ).item()
    
    # å½’ä¸€åŒ– anomaly_map
    normalized_anomaly_map = normalize_anomaly_map(
        merged_anomaly_map,
        PIXEL_THRESHOLD,    # threshold
        ANOMALY_MAP_MIN,    # min_val
        ANOMALY_MAP_MAX     # max_val
    )
    
    # åº”ç”¨ROI maskï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if roi_mask is not None:
        # å°†ROI maskè°ƒæ•´åˆ°512Ã—512
        roi_mask_resized = cv2.resize(roi_mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)
        roi_mask_tensor = torch.from_numpy(roi_mask_resized / 255.0).float().to(device)
        
        # åº”ç”¨maskï¼šROIå¤–çš„åŒºåŸŸanomalyå€¼è®¾ä¸º0
        normalized_anomaly_map = normalized_anomaly_map * roi_mask_tensor
        
        # é‡æ–°è®¡ç®—pred_scoreï¼ˆåªåŸºäºROIå†…çš„åŒºåŸŸï¼‰
        # è¿™æ ·pred_scoreåªåæ˜ ROIå†…çš„å¼‚å¸¸ç¨‹åº¦ï¼Œä¸å—ROIå¤–åŒºåŸŸå½±å“
        roi_area = roi_mask_tensor.sum().item()
        if roi_area > 0:
            # ROIå†…çš„å¹³å‡anomalyå€¼
            roi_anomaly_sum = (normalized_anomaly_map * roi_mask_tensor).sum().item()
            normalized_pred_score = roi_anomaly_sum / roi_area
        else:
            # å¦‚æœROIä¸ºç©ºï¼Œåˆ™pred_scoreè®¾ä¸º0
            normalized_pred_score = 0.0
        
        print(f"   ğŸ¯ å·²åº”ç”¨ROI maskï¼Œpred_scoreå·²é‡æ–°è®¡ç®—ï¼ˆä»…åŸºäºROIå†…åŒºåŸŸï¼‰")
    
    print(f"   ğŸ“Š å½’ä¸€åŒ–å:")
    print(f"      - Pred Score: {normalized_pred_score:.4f}")
    print(f"      - Anomaly Map æœ€å¤§å€¼: {normalized_anomaly_map.max().item():.4f}")
    
    # åˆ¤æ–­ç­–ç•¥ï¼šåŸºäºæ•´ä½“åˆ†æ•°
    # ============================================================
    # pred_score (æ•´ä½“åˆ†æ•°): åæ˜ æ•´å¼ å›¾çš„å¹³å‡å¼‚å¸¸ç¨‹åº¦
    # é˜ˆå€¼ä»é…ç½®æ–‡ä»¶è¯»å–: NORMALIZED_THRESHOLD
    # ============================================================
    
    # åŸºäºæ•´ä½“åˆ†æ•°åˆ¤æ–­
    if normalized_pred_score >= NORMALIZED_THRESHOLD:
        pred_label = "NG"
        reason = f"å¼‚å¸¸ï¼ˆåˆ†æ•° {normalized_pred_score:.3f} â‰¥ {NORMALIZED_THRESHOLD}ï¼‰"
    else:
        pred_label = "OK"
        reason = f"æ­£å¸¸ï¼ˆåˆ†æ•° {normalized_pred_score:.3f} < {NORMALIZED_THRESHOLD}ï¼‰"
    
    print(f"   âœ… åˆ¤æ–­ç»“æœ: {pred_label} - {reason}")
    
    # ç”¨äºå¯è§†åŒ–çš„åˆ†æ•°ï¼ˆä½¿ç”¨å½’ä¸€åŒ–åçš„pred_scoreï¼‰
    pred_score = normalized_pred_score
    
    # è°ƒæ•´å½’ä¸€åŒ–åçš„anomaly mapå°ºå¯¸åˆ°åŸå§‹å›¾åƒå¤§å°
    anomaly_map_resized = F.interpolate(
        normalized_anomaly_map.unsqueeze(0).unsqueeze(0),
        size=original_size[::-1],  # (height, width)
        mode='bilinear',
        align_corners=False
    ).squeeze()
    
    # ä¿å­˜å¯è§†åŒ–ç»“æœ
    print(f"   ğŸ’¾ ä¿å­˜å¯è§†åŒ–ç»“æœ...")
    save_original_and_overlay_with_info(
        str(image_path),
        anomaly_map_resized,
        pred_label,
        pred_score,
        save_dir=str(OUTPUT_DIR),
        image_obj=image,  # ä¼ é€’è£å‰ªåçš„å›¾åƒå¯¹è±¡
    )

print("\n" + "="*70)
print("[æ­¥éª¤ 6/6] âœ… æ‰€æœ‰é¢„æµ‹å®Œæˆï¼")
print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {OUTPUT_DIR}")
print("="*70)
print(f"\nğŸ’¡ Tiled Ensemble é¢„æµ‹æµç¨‹:")
print(f"   1ï¸âƒ£  Predict: æ¯ä¸ªtileç‹¬ç«‹é¢„æµ‹ï¼ˆåŸå§‹å€¼ï¼‰")
print(f"   2ï¸âƒ£  Merge: åˆå¹¶tilesçš„anomaly_mapå’Œpred_score(å¹³å‡)")
print(f"   3ï¸âƒ£  Normalize: åœ¨IMAGEçº§åˆ«å½’ä¸€åŒ–ï¼ˆthresholdâ†’0.5ï¼‰")
print(f"   4ï¸âƒ£  Threshold: ä½¿ç”¨pred_scoreåˆ¤æ–­ï¼ˆé˜ˆå€¼={NORMALIZED_THRESHOLD:.2f}ï¼‰")
print(f"\nğŸ“Š å‚æ•°:")
print(f"   - Pred Score èŒƒå›´: [{PRED_SCORE_MIN:.2f}, {PRED_SCORE_MAX:.2f}]")
print(f"   - Image Threshold: {IMAGE_THRESHOLD:.2f} â†’ å½’ä¸€åŒ–å = 0.50")
print(f"   - Anomaly Map èŒƒå›´: [{ANOMALY_MAP_MIN:.2f}, {ANOMALY_MAP_MAX:.2f}]")
print(f"   - Pixel Threshold: {PIXEL_THRESHOLD:.2f} â†’ å½’ä¸€åŒ–å = 0.50")
print(f"\nğŸ¯ åˆ¤æ–­è§„åˆ™:")
print(f"   - åˆ†æ•° â‰¥ {NORMALIZED_THRESHOLD:.2f} â†’ NG (å¼‚å¸¸)")
print(f"   - åˆ†æ•° < {NORMALIZED_THRESHOLD:.2f} â†’ OK (æ­£å¸¸)")
print(f"\nâš™ï¸  é…ç½®æ–‡ä»¶: {CONFIG_FILE.name}")
print("="*70)